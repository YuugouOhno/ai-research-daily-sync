# メインコマンド: 日次情報収集フルワークフロー

今日の情報収集を完全自動化するメインコマンドです。以下の処理を順次実行します：

## 実行フロー

### Step 1: 新着記事収集
- `document_list.md`から情報源URLを読み込み
- `last_run.txt`との比較で新着記事を特定
- WebFetchで各ソースの最新記事を取得
- `latest_blog.json`として構造化データを生成
- `last_run.txt`を今日の日付で更新

### Step 2: 記事詳細取得・要約生成
- `latest_blog.json`から各記事URLを読み込み
- WebFetchで記事の詳細内容を取得
- 各記事を個別要約ファイルとして生成
- ファイル形式: `YYYY/YYYY-MM-DD/[記事タイトル].md`

### Step 3: 手動クリップ処理（条件付き）
- `clips/`フォルダ内の`.md`ファイル存在をチェック
- **ファイルが存在する場合のみ**以下を実行：
  - 既存メタデータを抽出
  - 新テンプレート形式に変換
  - 今日のフォルダに移動
  - 元のclipsファイルを削除

### Step 4: 日次まとめ生成
- 今日生成された全個別記事ファイルを読み込み
- ソース別にグループ化
- `abstract.md`として統合サマリーを生成

## 実行手順

1. **初期設定確認**
   - 今日の日付取得（YYYY-MM-DD）
   - 必要なフォルダ構造の確認・作成

2. **Step 1: 新着記事収集実行**
   - document_list.md読み込み
   - last_run.txt基準日取得
   - 各情報源のWebFetch並列実行
   - latest_blog.json生成
   - last_run.txt更新

3. **Step 2: 記事詳細処理実行**
   - latest_blog.json解析
   - 各記事のWebFetch並列実行
   - 個別要約ファイル生成

4. **Step 3: clips処理（条件分岐）**
   - clips/フォルダの.mdファイル存在確認
   - 存在する場合：
     - 各ファイル読み込み・変換
     - 今日フォルダへ移動
     - 元ファイル削除
   - 存在しない場合：処理スキップ

5. **Step 4: 統合サマリー生成**
   - 今日フォルダ内の全.mdファイル読み込み
   - abstract.md生成

6. **処理結果レポート**
   - 各ステップの成功/失敗状況
   - 生成ファイル一覧
   - エラー詳細（あれば）

## 使用ツール
- **Bash**: 日付取得、フォルダ操作、ファイル削除
- **Read**: 設定ファイル・記事ファイル読み込み
- **Write**: JSON・Markdownファイル生成
- **WebFetch**: 記事内容取得
- **Glob/LS**: ファイル検索・一覧取得

## エラーハンドリング
- 各ステップでエラーが発生した場合は詳細を記録
- 部分的な失敗でも継続可能な処理は続行
- 最終レポートでエラー箇所を明示

## 実行時間目安
- Step 1: 2-3分（WebFetch並列処理）
- Step 2: 3-4分（記事詳細取得）
- Step 3: 30秒-1分（clips処理、条件次第）
- Step 4: 30秒（統合処理）
- **合計**: 約6-9分

---

**実行開始**: 上記フローに従って日次情報収集の完全自動化を実行してください。

**注意事項**:
- 処理中に他のタスクと競合しないよう注意
- 大量のWebFetch実行のため、適度な間隔での実行を推奨
- エラー時は各ステップの詳細ログを確認